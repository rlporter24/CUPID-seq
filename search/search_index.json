{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":""},{"location":"#cupid-seq","title":"CUPID-seq","text":"<p>CUPID-seq (Containerized Dual-Index Demultiplexing) is a containerized pipeline for demultiplexing dual-indexed 16S amplicon sequencing data. By packaging the analysis in Docker and Singularity/Apptainer images, CUPID-seq eliminates dependency installation headaches and ensures highly reproducible results across computing environments.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Containerized \u2014 runs in Docker or Singularity/Apptainer with zero dependency setup</li> <li>Reproducible \u2014 identical environments across local machines and HPC clusters</li> <li>Flexible \u2014 supports 13 pre-built 16S primer/index sets plus custom primers</li> <li>DADA2 Integration \u2014 optional downstream species inference with DADA2</li> </ul>"},{"location":"#pipeline-overview","title":"Pipeline Overview","text":"<p>The CUPID-seq pipeline processes paired-end amplicon reads through the following stages:</p> <ol> <li>Input validation \u2014 checks file paths, naming conventions, and samplesheet/fastqlist consistency</li> <li>Demultiplexing \u2014 separates reads by dual inline indexes (round 1 + round 2 barcodes)</li> <li>Trimming \u2014 removes index, spacer, and primer sequences from demultiplexed reads</li> <li>Grouped output \u2014 organizes trimmed reads into user-defined group subdirectories</li> </ol>"},{"location":"#read-structure","title":"Read Structure","text":"<p>The dual-index primer design uses variable-length phased indexes on both read 1 and read 2:</p> <p></p> <p></p>"},{"location":"#supported-16s-regions","title":"Supported 16S Regions","text":"<p>Pre-built index files are provided for the following regions. The default is V4.</p> Region Index File V1 - V2 <code>V1-V2_index_for_demux.txt</code> V1 - V3 <code>V1-V3_index_for_demux.txt</code> V2 - V3 <code>V2-V3_index_for_demux.txt</code> V3 <code>V3_index_for_demux.txt</code> V3 - V4 <code>V3-V4_index_for_demux.txt</code> V4 <code>V4_index_for_demux.txt</code> (default) V4 - V5 <code>V4-V5_index_for_demux.txt</code> V5 <code>V5_index_for_demux.txt</code> V5 - V7 <code>V5-V7_index_for_demux.txt</code> V6 <code>V6_index_for_demux.txt</code> V6 - V7 <code>V6-V7_index_for_demux.txt</code> V6 - V8 <code>V6-V8_index_for_demux.txt</code> V7 - V9 <code>V7-V9_index_for_demux.txt</code> <p>These files are located in the <code>other_index_for_demux/</code> directory of the repository.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started \u2014 install a container image and run your first analysis</li> <li>Configuration \u2014 detailed reference for config.yaml, input files, and custom primers</li> <li>Troubleshooting \u2014 common issues and solutions</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration","title":"Configuration","text":"<p>This page covers the container file structure, config.yaml settings, input file formats, and custom primer/index setup.</p>"},{"location":"configuration/#container-file-structure","title":"Container File Structure","text":"<p>The Docker and Singularity images create the following directory layout:</p> <p></p> <p>Within the main <code>16s-demux</code> directory:</p> <ul> <li><code>config/</code> \u2014 configuration files, fastq file list, samplesheet, and index files</li> <li><code>workflow/rules/</code> \u2014 analysis code</li> <li><code>workflow/out/</code> \u2014 output directory for real analyses</li> <li><code>workflow/test_out/</code> \u2014 output directory for test runs</li> <li><code>fastq_data/</code> \u2014 test sequencing data</li> </ul> <p>The Snakefile and Slurm submission scripts are in the top-level <code>16s-demux</code> directory.</p>"},{"location":"configuration/#configyaml-reference","title":"config.yaml Reference","text":"<p>The <code>config/config.yaml</code> file controls all pipeline settings. The key fields are:</p> Field Description Default <code>samplesheet</code> Path to the samplesheet file <code>samplesheet.txt</code> <code>indices</code> Path to the index file for demultiplexing <code>indexfordemux.txt</code> <code>fastqlist</code> Path to the fastq file list <code>fastq.txt</code> <code>lenR1index</code> Length of the read 1 index (longest phase) <code>7</code> <code>lenR2index</code> Length of the read 2 index (longest phase) <code>7</code> <code>lenR1primer</code> Length of read 1 primer (gene-specific + spacer) <code>23</code> <code>lenR2primer</code> Length of read 2 primer (gene-specific + spacer) <code>24</code> <p>All paths are relative to the <code>config/</code> directory unless absolute paths are provided.</p>"},{"location":"configuration/#input-files","title":"Input Files","text":"<p>Three inputs are required beyond the sequencing data itself: a fastq file list, a samplesheet, and the sequencing fastq data.</p> <p>Note</p> <p>Most common pipeline errors arise from input file formatting issues. The pipeline validates inputs automatically \u2014 check <code>workflow/out/inputCheck_log.txt</code> for any warnings.</p>"},{"location":"configuration/#fastq-data","title":"Fastq Data","text":"<p>Naming rules:</p> <ul> <li>Sample names must not contain spaces, underscores, or periods (hyphens are fine)</li> <li>Rename files before demultiplexing if they violate these rules</li> </ul> <p>Format:</p> <ul> <li>Gzipped fastq files (<code>.fastq.gz</code>)</li> </ul> <p>Location:</p> <p>Fastq files can be located anywhere accessible to the container. Their paths are defined by combining the <code>fastqdir</code> variable in <code>config.yaml</code> with the paths in the fastq file list.</p> <code>fastqdir</code> (config.yaml) Fastq file list entry <code>\"\"</code> <code>/home/users/TEST/sequencing/exp01/fastqs/TEST_R1_001.fastq.gz</code> <code>/home/users/TEST/sequencing/exp01/fastqs/</code> <code>TEST_R1_001.fastq.gz</code> <p>Tip</p> <p>Periods in sample names are accepted for demultiplexing but will cause issues with downstream tools like DADA2. Avoid them if you plan to use DADA2.</p>"},{"location":"configuration/#fastq-file-list","title":"Fastq File List","text":"<p>Location: Place in the <code>config/</code> directory and update the <code>fastqlist</code> field in <code>config.yaml</code> (default name: <code>fastq.txt</code>).</p> <p>Format: Tab-delimited text file with three columns:</p> Column Description <code>read1</code> Path to read 1 fastq.gz file <code>read2</code> Path to read 2 fastq.gz file <code>file</code> Shortened file identifier <p>The <code>file</code> column should use the format <code>{RunName}-{round2plate}-{well}</code>, where:</p> <ul> <li><code>RunName</code> \u2014 any identifier without underscores, spaces, or periods</li> <li><code>round2plate</code> \u2014 plate identifier for round 2 barcodes</li> <li><code>well</code> \u2014 well number</li> </ul> <p>Example:</p> read1 read2 file <code>../fastq_data/test_inputs/KKRP-001_S441_R1_001.fastq.gz</code> <code>../fastq_data/test_inputs/KKRP-001_S441_R2_001.fastq.gz</code> <code>15mc-003-P08B01-A01</code> <code>../fastq_data/test_inputs/KKRP-002_S442_R1_001.fastq.gz</code> <code>../fastq_data/test_inputs/KKRP-002_S442_R2_001.fastq.gz</code> <code>15mc-003-P08B01-A02</code> <p>Important</p> <p>The <code>file</code> field in the fastq file list must match the first part of the <code>filename</code> field in the samplesheet.</p>"},{"location":"configuration/#samplesheet","title":"Samplesheet","text":"<p>Location: Place in the <code>config/</code> directory and update the <code>samplesheet</code> field in <code>config.yaml</code> (default name: <code>samplesheet.txt</code>).</p> <p>Format: Tab-delimited file (<code>.tsv</code> or <code>.txt</code>) with a header row. Three columns are required:</p> Column Description <code>filename</code> Format: <code>{RunName}-{round2plate}-{well}-L{round1index}</code> <code>sample</code> Final sample name after demultiplexing (no underscores or periods) <code>group</code> Group identifier for output organization (no spaces or slashes) <p>Additional columns can be included freely \u2014 only <code>filename</code>, <code>sample</code>, and <code>group</code> are used by the pipeline.</p> <p>The <code>{RunName}-{round2plate}-{well}</code> portion of <code>filename</code> must match the corresponding <code>file</code> entries in the fastq file list. The <code>round1index</code> value should match the <code>phase</code> entry in the <code>indexfordemux.txt</code> table.</p> <p>Group behavior: Samples in different groups are output into separate subdirectories within <code>trimmed/</code>. If you don't need grouping, use a single group name for all samples or leave the column blank (keep the <code>group</code> header).</p> <p>Example (key columns shown):</p> filename sample group <code>15mc-003-P08B01-A01-L4</code> <code>P5-A01-plateP-wellA1</code> <code>group1</code> <code>15mc-003-P08B01-A02-L4</code> <code>P5-A02-plateP-wellA2</code> <code>group1</code> <code>15mc-003-P08B01-A01-L5</code> <code>P6-A01-plateW-wellA5</code> <code>group2</code> <code>15mc-003-P08B01-A02-L5</code> <code>P6-A02-plateW-wellA6</code> <code>group2</code>"},{"location":"configuration/#index-files","title":"Index Files","text":"<p>The <code>indexfordemux.txt</code> file contains the inline indexes used for demultiplexing. The default file uses the 16S V4 index set.</p>"},{"location":"configuration/#pre-built-index-sets","title":"Pre-built Index Sets","text":"<p>Index files for 13 regions are provided in the <code>other_index_for_demux/</code> directory:</p> Region File V1 - V2 <code>V1-V2_index_for_demux.txt</code> V1 - V3 <code>V1-V3_index_for_demux.txt</code> V2 - V3 <code>V2-V3_index_for_demux.txt</code> V3 <code>V3_index_for_demux.txt</code> V3 - V4 <code>V3-V4_index_for_demux.txt</code> V4 <code>V4_index_for_demux.txt</code> (default) V4 - V5 <code>V4-V5_index_for_demux.txt</code> V5 <code>V5_index_for_demux.txt</code> V5 - V7 <code>V5-V7_index_for_demux.txt</code> V6 <code>V6_index_for_demux.txt</code> V6 - V7 <code>V6-V7_index_for_demux.txt</code> V6 - V8 <code>V6-V8_index_for_demux.txt</code> V7 - V9 <code>V7-V9_index_for_demux.txt</code> <p>To use a different region, copy the appropriate file into <code>config/</code> and update the <code>indices</code> field in <code>config.yaml</code>.</p> <p>Tip</p> <p>For all pre-built index sets, the default <code>config.yaml</code> length parameters are correct \u2014 no changes needed for <code>lenR1index</code>, <code>lenR2index</code>, <code>lenR1primer</code>, or <code>lenR2primer</code>.</p>"},{"location":"configuration/#custom-index-files","title":"Custom Index Files","text":"<p>If you are using custom primers, you need to create a custom <code>indexfordemux.txt</code> file and may need to update the length parameters in <code>config.yaml</code>.</p> <p>An Excel template (<code>other_index_for_demux.xlsx</code>) is provided in the <code>other_index_for_demux/</code> directory to help derive custom index files.</p>"},{"location":"configuration/#understanding-the-read-structure","title":"Understanding the Read Structure","text":"<p>The final read structure after library prep looks like this (lengths not to scale):</p> <p></p> <p>The round 1 indexes use variable-length \"phases\" (0\u20137). Each phase has a different number of index bases, with the remaining positions filled by spacer and gene-specific primer sequence:</p> Phase Variable FP Variable RP 0 <code>ATGGACT</code> 1 <code>T</code> <code>GCTAGC</code> 2 <code>GG</code> <code>TGACT</code> 3 <code>ACT</code> <code>CGGT</code> 4 <code>TAAC</code> <code>GTA</code> 5 <code>CAGTC</code> <code>AA</code> 6 <code>ATCGAT</code> <code>C</code> 7 <code>GCAAGTC</code> <p></p> <p>During demultiplexing, reads are treated as having 7 base pair indexes on both ends. Any positions not filled by the actual index contain spacer or gene-specific primer sequence. In the default V4 index set:</p> <ul> <li>Underlined = actual index bases</li> <li>lowercase = spacer bases</li> <li>BOLD UPPERCASE = gene-specific primer region</li> </ul> Phase read1index read2index bc 0 cagtAGA ATGGACT CAGTAGAATGGACT 1 TcagtAG GCTAGCa TCAGTAGGCTAGCA 2 GGcagtA TGACTat GGCAGTATGACTAT 3 ACTcagt CGGTatc ACTCAGTCGGTATC 4 TAACcag GTAatcc TAACCAGGTAATCC 5 CAGTCca AAatccT CAGTCCAAAATCCT 6 ATCGATc CatccTA ATCGATCCATCCTA 7 GCAAGTC atccTAC GCAAGTCATCCTAC"},{"location":"configuration/#changing-only-the-gene-specific-region","title":"Changing Only the Gene-Specific Region","text":"<p>If you use the same primer design and index scheme but target a different gene, only the gene-specific regions within the indexes need to change.</p> <p>Example: For the default V4 primers, the gene starts with <code>AGA...</code> and ends with <code>GTA</code> on the forward strand, giving regions of homology <code>AGA</code> and <code>TAC</code> (both 5' to 3').</p> <p>For a gene reading <code>ATG ... CGT</code>, the regions of homology become <code>ATG</code> and <code>ACG</code> (both 5' to 3'). The updated index table would be:</p> Phase read1index read2index bc 0 cagtATG ATGGACT CAGTAGAATGGACT 1 TcagtAT GCTAGCa TCAGTAGGCTAGCA 2 GGcagtA TGACTat GGCAGTATGACTAT 3 ACTcagt CGGTatc ACTCAGTCGGTATC 4 TAACcag GTAatcc TAACCAGGTAATCC 5 CAGTCca AAatccA CAGTCCAAAATCCT 6 ATCGATc CatccAC ATCGATCCATCCTA 7 GCAAGTC atccACG GCAAGTCATCCTAC <p>Only the gene-specific regions (bold) have changed \u2014 index and spacer sequences remain identical.</p> <p>Mixed Base Characters</p> <p>Avoid mixed base characters such as <code>W</code> or <code>N</code> in the first three positions of your gene-specific primer. If such bases are present, you must include extra entries in the <code>indexfordemux.txt</code> table \u2014 one for each possible base (e.g., for <code>W</code>, one entry with <code>A</code> and one with <code>T</code>). Each affected sample should appear twice in the samplesheet, and the output files will need to be merged downstream.</p>"},{"location":"configuration/#updating-length-parameters","title":"Updating Length Parameters","text":"<p>If your custom primers change the index or primer lengths, update <code>config.yaml</code>:</p> Parameter Description Default <code>lenR1index</code> Longest read 1 index length <code>7</code> <code>lenR2index</code> Longest read 2 index length <code>7</code> <code>lenR1primer</code> Gene-specific primer + spacer length (read 1) <code>23</code> <code>lenR2primer</code> Gene-specific primer + spacer length (read 2) <code>24</code> <p>Note</p> <p>For all pre-built 16S index sets (V1\u2013V2 through V7\u2013V9), the default length values are correct and do not need to be changed.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>This guide walks through setting up a container image, running the test analysis, and processing your own data.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker (install) or Singularity/Apptainer (available on most HPC systems)</li> <li>At least 4 GB RAM allocated to the container</li> <li>Paired-end sequencing data as <code>.fastq.gz</code> files</li> </ul>"},{"location":"getting-started/#step-1-obtain-the-container-image","title":"Step 1: Obtain the Container Image","text":"DockerSingularity/Apptainer"},{"location":"getting-started/#pull-from-docker-hub-recommended","title":"Pull from Docker Hub (Recommended)","text":"<p>Launch Docker, then run:</p> <pre><code>docker pull rlporter24/dualindex-demux:1.0\n</code></pre> <p>This downloads the pre-built image containing all code, dependencies, and test data.</p> Advanced: Build from Dockerfile <p>If you prefer to build the image yourself, download <code>docker-demux.zip</code> from the Zenodo repository and unzip it. The file structure should look like:</p> <p></p> <p><code>Dockerfile</code> and <code>requirements.txt</code> are needed for the build. The <code>fastq_data</code> directory contains test data, and all analysis code lives in <code>16s-demux/</code>.</p> <p>Build the image:</p> <pre><code>docker build -t {name}:{version} .\n</code></pre> <p>Replace <code>{name}:{version}</code> with your desired image name and version tag. The build takes a few minutes. A successful build ends with output like:</p> <p></p> <p>Warning</p> <p>Building requires more resources than a typical HPC login node provides. Use a compute node or allocate sufficient resources through a job manager.</p>"},{"location":"getting-started/#build-from-definition-file","title":"Build from Definition File","text":"<p>Download <code>demux.zip</code> from the Zenodo repository and unzip it. The file structure should look like:</p> <p></p> <p><code>16s-demux.def</code> and <code>requirements.txt</code> are needed for the build. The <code>fastq_data</code> directory contains test data, and all code lives in <code>16s-demux/</code>.</p> <p>Navigate to the directory containing <code>16s-demux.def</code> and build:</p> <pre><code>singularity build demux-image.sif 16s-demux.def\n</code></pre> <p>The build takes less than 10 minutes. A successful build ends with output like:</p> <p></p> <p>The file <code>demux-image.sif</code> will be created in your current working directory.</p> <p>Warning</p> <p>Building requires more resources than a typical HPC login node provides. Use a compute node or a job manager. A template Slurm script (<code>slurmBuild.sh</code>) is included in <code>demux.zip</code> \u2014 edit the SBATCH parameters for your system.</p>"},{"location":"getting-started/#step-2-run-the-test-analysis","title":"Step 2: Run the Test Analysis","text":"<p>Run the included test data to verify your setup works correctly.</p> DockerSingularity/Apptainer <p>Start an interactive container:</p> <pre><code>docker run -it rlporter24/dualindex-demux:1.0\n</code></pre> <p>Note</p> <p>If you built your own image, replace <code>rlporter24/dualindex-demux:1.0</code> with the <code>{name}:{version}</code> you used.</p> <p>All test files are included in the container. Run the test:</p> <pre><code>snakemake --cores 1 -s test_Snakefile\n</code></pre> <p>Replace <code>1</code> with the desired number of cores. This should complete in under 5 minutes.</p> <p>Interactive mode:</p> <p>Open a shell in the container:</p> <pre><code>singularity shell demux-image.sif\n</code></pre> <p>Run the test from the <code>16s-demux</code> directory:</p> <pre><code>snakemake --cores 1 -s test_Snakefile\n</code></pre> <p>Using a job manager (e.g., Slurm):</p> <p>Edit the included <code>submit_test_snakemake.sh</code> script for your system, then submit it. The script runs:</p> <pre><code>singularity exec ../demux-image.sif snakemake --cores 1 -s test_Snakefile\n</code></pre> <p>Replace <code>1</code> with the desired number of cores. This should complete in about 10 minutes.</p>"},{"location":"getting-started/#verifying-test-output","title":"Verifying Test Output","text":"<p>A successful test run produces output like:</p> <p></p> <p>Within <code>workflow/test_out/</code>, you should see <code>demux</code> and <code>trimmed</code> directories:</p> <ul> <li> <p><code>demux/</code> \u2014 four sets of 3 files (1 <code>.extract.log</code> + 2 <code>.fastq.gz</code> each), plus <code>R1/</code> and <code>R2/</code> directories. Each sample should have 8 files ending with <code>-L*.fastq.gz</code> (phases 0\u20137):</p> <p></p> </li> <li> <p><code>trimmed/</code> \u2014 subdirectories <code>group1</code> and <code>group2</code>, each containing <code>R1/</code>, <code>R2/</code>, <code>removed/</code>, plus <code>lowReadsSummary.txt</code> and <code>summary.txt</code>:</p> <p></p> </li> </ul> <p>Success</p> <p>If all these files are present, the test run was successful.</p>"},{"location":"getting-started/#step-3-run-your-analysis","title":"Step 3: Run Your Analysis","text":"DockerSingularity/Apptainer <p>1. Start a container:</p> <pre><code>docker run -it rlporter24/dualindex-demux:1.0\n</code></pre> <p>2. Copy input files into the container:</p> <p>From a separate terminal, use <code>docker cp</code> to transfer your data:</p> <pre><code>docker cp {local_path} {CONTAINER}:{container_path}\n</code></pre> <ul> <li><code>{local_path}</code> \u2014 path to a file or directory on your machine</li> <li><code>{CONTAINER}</code> \u2014 the container name (find it with <code>docker container ls</code>)</li> <li><code>{container_path}</code> \u2014 destination path relative to the <code>16s-demux</code> directory</li> </ul> <p>Tip</p> <p>Find your container name by running <code>docker container ls</code> or checking the Docker Desktop GUI.</p> <p>3. Update configuration:</p> <p>Edit <code>config/config.yaml</code> to set the paths for your <code>samplesheet</code>, <code>fastqlist</code>, and (if needed) <code>indices</code> file. See the Configuration page for details.</p> <p>4. Dry run (recommended):</p> <pre><code>snakemake -n\n</code></pre> <p>This validates inputs and shows planned jobs without executing them.</p> <p>5. Execute:</p> <pre><code>snakemake --cores 1\n</code></pre> <p>Replace <code>1</code> with the desired number of cores. A successful run ends with:</p> <p></p> <p>6. Transfer outputs:</p> <pre><code>docker cp {CONTAINER}:/16s-demux/workflow/out/ {local_path}\n</code></pre> <p>7. Clean up:</p> <p>Exit the container (<code>exit</code>), then remove it:</p> <pre><code>docker rm {container_name}\n</code></pre> <p>Warning</p> <p>This removes the container and all data inside it. Make sure all outputs are transferred before removing.</p> <p>1. Prepare inputs:</p> <p>Ensure your input files (fastq data, fastqlist, samplesheet) are accessible on the file system. Update <code>config/config.yaml</code> with the correct paths. See the Configuration page for details.</p> <p>2. Dry run (recommended):</p> InteractiveJob Manager <pre><code>singularity shell demux-image.sif\nsnakemake -n\n</code></pre> <p>Submit a job that runs:</p> <pre><code>singularity exec ../demux-image.sif snakemake -n\n</code></pre> <p>3. Execute:</p> InteractiveJob Manager <pre><code>snakemake --cores 1\n</code></pre> <p>Edit the included <code>submit_snakemake.sh</code> script with your SBATCH parameters, then submit. The script runs:</p> <pre><code>singularity exec ../demux-image.sif snakemake --cores 1\n</code></pre> <p>Replace <code>1</code> with the desired number of cores. A successful run ends with:</p> <p></p> <p>Outputs are generated in <code>workflow/out/</code>. To exit an interactive shell, type <code>exit</code>.</p> <p>Note</p> <p>Running interactively is only recommended for testing or troubleshooting. Login nodes typically lack sufficient resources \u2014 use a compute node or job manager for real analyses.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<p>This page covers common issues encountered when running the CUPID-seq pipeline.</p>"},{"location":"troubleshooting/#input-validation","title":"Input Validation","text":"<p>The pipeline automatically checks inputs as its first step. Review the validation log for any warnings:</p> <ul> <li>Real runs: <code>16s-demux/workflow/out/inputCheck_log.txt</code></li> <li>Test runs: <code>16s-demux/workflow/test_out/inputCheck_log.txt</code></li> </ul> <p>Success</p> <p>If the log only reads <code>All done!</code>, no input issues were detected.</p> <p>You can also run a dry run before starting the full analysis to catch missing files and configuration errors:</p> <pre><code>snakemake -n\n</code></pre> <p>This determines all jobs that would be run and reports any missing inputs, without executing anything. You must run this inside a Docker container or Singularity shell.</p>"},{"location":"troubleshooting/#common-input-issues","title":"Common Input Issues","text":""},{"location":"troubleshooting/#sample-naming-errors","title":"Sample Naming Errors","text":"<p>Problem: Sample names contain spaces, underscores, or periods.</p> <p>Solution: Rename fastq files and update the fastq file list and samplesheet so that sample names use only alphanumeric characters and hyphens.</p> <p>Tip</p> <p>Periods are accepted by the demultiplexing pipeline but will cause errors with downstream tools like DADA2. Remove them if you plan to use DADA2.</p>"},{"location":"troubleshooting/#fastqlist-samplesheet-mismatch","title":"Fastqlist / Samplesheet Mismatch","text":"<p>Problem: The <code>file</code> column in the fastq file list doesn't match the <code>filename</code> column in the samplesheet.</p> <p>Solution: The <code>filename</code> field in the samplesheet should follow the format <code>{RunName}-{round2plate}-{well}-L{round1index}</code>, where the <code>{RunName}-{round2plate}-{well}</code> portion exactly matches the <code>file</code> entries in the fastq file list. Check for typos, extra whitespace, or inconsistent naming.</p>"},{"location":"troubleshooting/#wrong-file-paths","title":"Wrong File Paths","text":"<p>Problem: The pipeline can't find fastq files.</p> <p>Solution: Verify that the <code>fastqdir</code> variable in <code>config.yaml</code> combined with the paths in your fastq file list produces valid absolute paths. Check that files exist at those locations within the container.</p>"},{"location":"troubleshooting/#wrong-index-file","title":"Wrong Index File","text":"<p>Problem: Using the default V4 index file when targeting a different 16S region.</p> <p>Solution: Copy the correct index file from <code>other_index_for_demux/</code> into <code>config/</code> and update the <code>indices</code> field in <code>config.yaml</code>. See the Configuration page for the full list of available index files.</p>"},{"location":"troubleshooting/#resource-issues","title":"Resource Issues","text":""},{"location":"troubleshooting/#insufficient-memory","title":"Insufficient Memory","text":"<p>Problem: The pipeline fails at a consistent stage with hard-to-interpret errors.</p> <p>Solution: Allocate at least 4 GB of memory. For building images and running the test, 4 GB and one core are sufficient, but larger allocations will speed up processing. If errors reliably occur at the same stage, insufficient memory is a likely cause.</p>"},{"location":"troubleshooting/#build-failures-on-login-nodes","title":"Build Failures on Login Nodes","text":"<p>Problem: Image building fails or is killed on an HPC login node.</p> <p>Solution: Login nodes typically have strict resource limits. Build images on a compute node or submit the build as a job:</p> DockerSingularity/Apptainer <p>Use a compute node with Docker access:</p> <pre><code>docker build -t {name}:{version} .\n</code></pre> <p>Use the included Slurm template:</p> <pre><code># Edit slurmBuild.sh with appropriate SBATCH parameters, then:\nsbatch slurmBuild.sh\n</code></pre>"},{"location":"troubleshooting/#docker-specific-issues","title":"Docker-Specific Issues","text":""},{"location":"troubleshooting/#finding-the-container-name","title":"Finding the Container Name","text":"<p>Problem: You need the container name for <code>docker cp</code> commands but don't know it.</p> <p>Solution: List running containers:</p> <pre><code>docker container ls\n</code></pre> <p>Or check the Docker Desktop GUI under the Containers tab.</p>"},{"location":"troubleshooting/#files-lost-after-exiting","title":"Files Lost After Exiting","text":"<p>Problem: Output files are gone after exiting the container.</p> <p>Solution: Always transfer output files before exiting:</p> <pre><code>docker cp {CONTAINER}:/16s-demux/workflow/out/ {local_path}\n</code></pre> <p>Once you exit and remove a container (<code>docker rm</code>), all data inside is permanently deleted. The image itself is preserved and can be used to start new containers.</p>"},{"location":"troubleshooting/#singularity-specific-issues","title":"Singularity-Specific Issues","text":""},{"location":"troubleshooting/#interactive-vs-job-manager","title":"Interactive vs. Job Manager","text":"<p>Problem: Analysis is too slow or gets killed when running interactively.</p> <p>Solution: Interactive mode (<code>singularity shell</code>) is only recommended for testing and troubleshooting. For real analyses, submit jobs through your cluster's job manager:</p> <pre><code>singularity exec ../demux-image.sif snakemake --cores 1\n</code></pre> <p>A draft Slurm submission script (<code>submit_snakemake.sh</code>) is included. Edit the SBATCH parameters at the top for your system.</p>"},{"location":"troubleshooting/#dada2-specific-issues","title":"DADA2-Specific Issues","text":""},{"location":"troubleshooting/#silva-species-level-error","title":"Silva Species-Level Error","text":"<p>Problem: The DADA2 pipeline raises an error when using the Silva database at the species level.</p> <p>Solution: The Silva database (<code>silva_nr_v132_train_set.fa.gz</code>) does not support species-level (L7) resolution. If using Silva, edit <code>workflow/scripts/summary_taxa.R</code>:</p> <ol> <li>Update line 14 to point to the Silva database:     <pre><code>ref_fasta &lt;- \"/databases/silva_nr_v132_train_set.fa.gz\"\n</code></pre></li> <li>Comment out lines 93\u2013106 of <code>summary_taxa.R</code> to skip species-level inference.</li> </ol> <p>The default GreenGenes database (<code>gg_13_8_train_set_97.fa.gz</code>) supports all taxonomic levels including species.</p>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If your issue isn't covered here, please open a GitHub Issue with:</p> <ul> <li>A description of the error</li> <li>The contents of <code>inputCheck_log.txt</code> (if applicable)</li> <li>The command you ran and any error output</li> <li>Your container type (Docker or Singularity) and version</li> </ul>"}]}